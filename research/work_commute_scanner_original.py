# -*- coding: utf-8 -*-
"""work_commute_scanner.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D3B2PKAytJ20NxQYqrIFyXQuh0Seh-Vo

# Työmatka-skanneri: yritysrekisteri x juna-asemat

Tämä notebook hakee **PRH:n Opendata YTJ -rajapinnasta** yrityksiä valituista kaupungeista ja valinnaisilla toimialasuodattimilla (TOL 2008),
geokoodaa niiden osoitteet, ja mittaa etäisyyden **lähimpään juna-asemaan**. Lopuksi saat Excel-raportin ja Folium-kartan.

**Lähteet:**
- PRH Opendata YTJ API (v3) – `/companies`, sivutus ja suodatus (nimi, sijainti, toimiala…)
- Asemat: Trainline `stations.csv` (sis. Suomi) tai vaihtoehtoisesti oma CSV asemapisteistä.

⚠️ **Huom:** Geokoodaus käyttää Nominatim/OSM:ää -> lisää `user_agent` ja pidä tahti maltillisena (1 rq/s). Välimuisti estää saman osoitteen toistogeokoodauksen.
"""

#@title Asennukset
!pip -q install pandas requests tqdm rapidfuzz geopy folium openpyxl unidecode

#@title Asetukset
from datetime import date

# Kohdekaupungit (YTJ API:n location-parametriin)
TARGET_CITIES = ["Helsinki", "Espoo", "Vantaa", "Mäntsälä", "Lahti"]  #@param {type:"raw"}

# TOL 2008 päätoimialasuodatin (voi olla koodi tai teksti; jätä tyhjäksi jos ei tarvita)
MAIN_BUSINESS_LINE = ""  #@param {type:"string"}

# Rekisteröintipäivähaarukka (valinnainen)
REG_START = ""  #@param {type:"string"}
REG_END   = ""  #@param {type:"string"}

# Etäisyysraja (km) asemalle
RADIUS_KM = 1.0  #@param {type:"number"}

# Maksimi sivut per kaupunki (turvaraja kehitysvaiheessa). 0 = hae kaikki sivut.
MAX_PAGES_PER_CITY = 0  #@param {type:"integer"}

# Tulostiedostot
OUTPUT_EXCEL = "companies_near_stations.xlsx"
OUTPUT_GEOJSON = "companies_near_stations.geojson"
OUTPUT_HTML_MAP = "companies_near_stations_map.html"

#@title Kirjastot ja apufunktiot
import os
import time
import math
import json
import requests
import pandas as pd
from tqdm.auto import tqdm
from unidecode import unidecode
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter
import folium

PRH_BASE = "https://avoindata.prh.fi/opendata-ytj-api/v3"

def haversine_km(lat1, lon1, lat2, lon2):
    R = 6371.0088
    phi1, phi2 = math.radians(lat1), math.radians(lat2)
    dphi = math.radians(lat2 - lat1)
    dlambda = math.radians(lon2 - lon1)
    a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2
    return 2*R*math.asin(math.sqrt(a))

def clean_address(street, post_code, city):
    parts = [p.strip() for p in [street or "", f"{post_code or ''}", city or ""] if p and p.strip()]
    s = ", ".join(parts)
    # Finnish -> ASCII backup for geocoder fallbacks
    return unidecode(s)

def fetch_prh_companies(location: str, main_business_line: str = "", reg_start: str = "", reg_end: str = "", max_pages: int = 0):
    """Iteroi PRH /companies -endpointti sivutettuna valitulle kaupungille.
    Palauttaa listan dict-olioita (raaka API-rivit)."""
    companies = []
    page = 0
    while True:
        params = {
            "location": location,
            "page": page,
        }
        if main_business_line:
            params["mainBusinessLine"] = main_business_line
        if reg_start:
            params["registrationDateStart"] = reg_start
        if reg_end:
            params["registrationDateEnd"] = reg_end

        r = requests.get(f"{PRH_BASE}/companies", params=params, timeout=60)
        r.raise_for_status()
        data = r.json()
        rows = data.get("companies", []) or data.get("results", []) or []
        total = data.get("totalResults")
        if not rows:
            break
        companies.extend(rows)
        page += 1
        if max_pages and page >= max_pages:
            break
        # Lopeta jos haettu kaikki sivut (kun 100 riviä/sivu ja tuloksia alle 100 seuraavalla sivulla)
        if total is not None and page*100 >= int(total):
            break
    return companies

def download_stations_csv():
    """Lataa Trainline stations.csv (sis. Eurooppa) ja suodattaa Suomen asemat.
    Vaihtoehtoisesti voit korvata tämän omalla, kuratoidulla CSV:llä.
    """
    url = "https://raw.githubusercontent.com/trainline-eu/stations/master/stations.csv"
    r = requests.get(url, timeout=60)
    r.raise_for_status()
    import io
    df = pd.read_csv(io.StringIO(r.text), sep=';')
    # Suodata Suomi (country == 'FI') ja pidä vain uniikit asemat, joilla koordinaatit
    df = df[df['country'] == 'FI'].copy()
    df = df.dropna(subset=['latitude','longitude'])
    df = df.rename(columns={"latitude":"lat","longitude":"lon","name":"station_name"})
    # Pidä vain tärkeimmät sarakkeet
    keep = ["station_name","lat","lon","uic","city_name","country"]
    keep = [c for c in keep if c in df.columns]
    return df[keep]

#@title Hae yritykset PRH:sta (YTJ API)
all_rows = []
for city in tqdm(TARGET_CITIES, desc="Kaupungit"):
    rows = fetch_prh_companies(location=city, main_business_line=MAIN_BUSINESS_LINE,
                               reg_start=REG_START, reg_end=REG_END, max_pages=MAX_PAGES_PER_CITY)
    for r in rows:
        r["_source_city"] = city
    all_rows.extend(rows)

raw_df = pd.json_normalize(all_rows)
print(f"Rivejä haettu: {len(raw_df)}")
raw_df.head(3)

#@title Esipuhdistus: rakenna geokoodattava osoite
if raw_df.empty:
    raise SystemExit("Ei rivejä haettu — säädä hakuasetuksia ja aja uudelleen.")

# Oletetaan sarakkeet; varmistetaan varavaihtoehdot
addr_cols = {
    "street": [
        "addresses.0.street",  # uudempi malli
        "street",               # fallback
    ],
    "postCode": [
        "addresses.0.postCode",
        "postCode",
    ],
    "city": [
        "addresses.0.city",
        "city",
        "domicile",
    ],
}

def first_nonnull(row, candidates):
    for c in candidates:
        if c in row and pd.notna(row[c]) and str(row[c]).strip():
            return str(row[c])
    return ""

prep = []
for _, row in raw_df.iterrows():
    street = first_nonnull(row, addr_cols["street"])
    postc  = first_nonnull(row, addr_cols["postCode"])
    city   = first_nonnull(row, addr_cols["city"]) or row.get("_source_city", "")
    full   = clean_address(street, postc, city)
    prep.append(full)

raw_df["full_address"] = prep
raw_df.head(3)

#@title Geokoodaus (välimuisti + maltillinen tahti)
geo = Nominatim(user_agent="work-commute-scanner")
geocode = RateLimiter(geo.geocode, min_delay_seconds=1.0, swallow_exceptions=True)

cache = {}
latitudes, longitudes = [], []
for addr in tqdm(raw_df["full_address"], desc="Geokoodaus"):
    if addr in cache:
        loc = cache[addr]
    else:
        loc = geocode(addr + ", Finland")
        cache[addr] = loc
    if loc is None:
        latitudes.append(None)
        longitudes.append(None)
    else:
        latitudes.append(loc.latitude)
        longitudes.append(loc.longitude)

raw_df["lat"] = latitudes
raw_df["lon"] = longitudes
geo_df = raw_df.dropna(subset=["lat","lon"]).copy()
print(f"Geokoodattu: {len(geo_df)} / {len(raw_df)}")
geo_df.head(3)

#@title Asema-aineisto (Trainline stations.csv) -> Suomi
stations_df = download_stations_csv()
print(stations_df.head(3))
print(f"Asemia (FI): {len(stations_df)}")

#@title Lähimmän aseman etäisyys ja suodatus
import numpy as np

stations_np = stations_df[["lat","lon"]].to_numpy()

nearest_name, nearest_km = [], []
for _, r in tqdm(geo_df.iterrows(), total=len(geo_df), desc="Etäisyydet"):
    lat, lon = float(r["lat"]), float(r["lon"])
    # Vektoroitu lasku voisi olla nopeampi, mutta pidetään selkeänä:
    dists = [haversine_km(lat, lon, slat, slon) for slat, slon in stations_np]
    i = int(np.argmin(dists))
    nearest_name.append(stations_df.iloc[i]["station_name"])
    nearest_km.append(dists[i])

geo_df["nearest_station"] = nearest_name
geo_df["distance_km"] = np.array(nearest_km)
near_df = geo_df[geo_df["distance_km"] <= RADIUS_KM].copy()
print(f"Yrityksiä säteellä {RADIUS_KM} km: {len(near_df)}")
near_df.head(5)

#@title Excel- ja karttavienti
cols_out = [
    "businessId" if "businessId" in near_df.columns else "businessId.value",
    "name" if "name" in near_df.columns else ("names.0.name" if "names.0.name" in near_df.columns else None),
    "full_address","_source_city","lat","lon","nearest_station","distance_km",
    "mainBusinessLine" if "mainBusinessLine" in near_df.columns else None
]
cols_out = [c for c in cols_out if c and c in near_df.columns]
report_df = near_df[cols_out].sort_values("distance_km").reset_index(drop=True)
report_df.to_excel(OUTPUT_EXCEL, index=False)
print(f"Tallennettu: {OUTPUT_EXCEL}")

# GeoJSON
features = []
for _, r in report_df.iterrows():
    props = r.to_dict()
    lat, lon = float(r["lat"]), float(r["lon"])
    features.append({
        "type": "Feature",
        "geometry": {"type": "Point", "coordinates": [lon, lat]},
        "properties": props
    })
geojson = {"type":"FeatureCollection","features":features}
with open(OUTPUT_GEOJSON, "w", encoding="utf-8") as f:
    json.dump(geojson, f, ensure_ascii=False)
print(f"Tallennettu: {OUTPUT_GEOJSON}")

# Folium-kartta
if len(report_df):
    center = [report_df["lat"].mean(), report_df["lon"].mean()]
else:
    center = [60.17, 24.94]
m = folium.Map(location=center, zoom_start=9)
for _, r in report_df.iterrows():
    folium.Marker([r["lat"], r["lon"]],
                  popup=f"{r.get('name', '')} — {r.get('nearest_station','')} ({r.get('distance_km',0):.2f} km)")\
          .add_to(m)
m.save(OUTPUT_HTML_MAP)
print(f"Tallennettu: {OUTPUT_HTML_MAP}")

"""### Vinkkejä jatkoon
- Vaihda **asemadata** omaan viralliseen CSV:hen (Väylävirasto/Traficom shapefile -> CSV), jos haluat täydellisen kattavuuden.
- Lisää **SQLite-välimuisti** geokoodaukselle (osoite -> lat/lon), jos ajat usein.
- Lisää **yrityslinkit** ja muut PRH:n palauttamat metatiedot Exceliin.
- Lisää **TOL-suodatus** ja useiden koodien tuki (esim. pilkulla eroteltu lista -> for-loop).
"""